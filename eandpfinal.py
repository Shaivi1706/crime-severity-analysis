# -*- coding: utf-8 -*-
"""EANDPFINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Oa2-oLsvlviqGa8atenelygOAGFO3LsE
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.preprocessing import LabelEncoder
from imblearn.combine import SMOTETomek
import matplotlib.pyplot as plt
import seaborn as sns

# ----------------- 1. Load & Initial cleanup -----------------
df = pd.read_csv("/content/crime_dataset_india.csv")
drop_cols = ['Report Number', 'Crime Code', 'Case Closed', 'Date Case Closed']
df.drop(columns=drop_cols, inplace=True)
df["Crime Description"].unique()

# ----------------- 2. Date & Time Features -----------------
df['Date of Occurrence'] = pd.to_datetime(df['Date of Occurrence'], format='%d-%m-%Y %H:%M', errors='coerce')
df['Time of Occurrence'] = pd.to_datetime(df['Time of Occurrence'].astype(str), format='%d-%m-%Y %H:%M', errors='coerce').dt.time
df['Day'] = df['Date of Occurrence'].dt.dayofweek.apply(lambda x: 'Weekend' if x >= 5 else 'Weekday')
df['Hour'] = pd.to_datetime(df['Time of Occurrence'].astype(str), errors='coerce').dt.hour.fillna(-1).astype(int)

time_bins = [-2, -0.1, 5, 11, 15, 17, 23]
time_labels = ['Unknown', 'Night', 'Morning', 'Afternoon', 'Evening', 'Late Night']
df['Time of Day'] = pd.cut(df['Hour'], bins=time_bins, labels=time_labels, right=True, include_lowest=True)

df.drop(columns=['Date of Occurrence', 'Time of Occurrence', 'Hour'], inplace=True)

# ----------------- 3. Location Feature Mapping -----------------
city_to_state = {
    'Delhi': 'Delhi', 'Mumbai': 'Maharashtra', 'Bangalore': 'Karnataka', 'Hyderabad': 'Telangana',
    'Kolkata': 'West Bengal', 'Chennai': 'Tamil Nadu', 'Pune': 'Maharashtra', 'Ahmedabad': 'Gujarat',
    'Jaipur': 'Rajasthan', 'Lucknow': 'Uttar Pradesh', 'Kanpur': 'Uttar Pradesh', 'Surat': 'Gujarat',
    'Nagpur': 'Maharashtra', 'Agra': 'Uttar Pradesh', 'Ludhiana': 'Punjab', 'Visakhapatnam': 'Andhra Pradesh',
    'Thane': 'Maharashtra', 'Ghaziabad': 'Uttar Pradesh', 'Indore': 'Madhya Pradesh', 'Patna': 'Bihar',
    'Bhopal': 'Madhya Pradesh', 'Meerut': 'Uttar Pradesh', 'Srinagar': 'Jammu & Kashmir', 'Nashik': 'Maharashtra',
    'Vasai': 'Maharashtra', 'Varanasi': 'Uttar Pradesh', 'Kalyan': 'Maharashtra', 'Faridabad': 'Haryana',
    'Rajkot': 'Gujarat'
}
state_to_region = {
    'Delhi': 'North', 'Punjab': 'North', 'Haryana': 'North', 'Jammu & Kashmir': 'North', 'Uttar Pradesh': 'North',
    'Karnataka': 'South', 'Tamil Nadu': 'South', 'Andhra Pradesh': 'South', 'Telangana': 'South',
    'West Bengal': 'East', 'Bihar': 'East', 'Gujarat': 'West', 'Maharashtra': 'West', 'Rajasthan': 'West',
    'Madhya Pradesh': 'Central'
}
df['State'] = df['City'].map(city_to_state)
df['Region'] = df['State'].map(state_to_region)
df.drop(columns=['City', 'State'], inplace=True)


# ----------------- 4. Handle Missing Values -----------------
df['Weapon Used'] = df['Weapon Used'].fillna('Unknown')
df['Victim Gender'] = df['Victim Gender'].fillna('Unknown')
df['Victim Age'] = df['Victim Age'].fillna(df['Victim Age'].median())

# Victim Age Groups
age_bins = [0,12,18,60,120]
age_labels = ['Child','Teenager','Adult','Senior']
df['Victim Age Group'] = pd.cut(df['Victim Age'], bins=age_bins, labels=age_labels, right=False)
df.drop(columns=['Victim Age'], inplace=True)

# ----------------- 5. Severity Label Creation -----------------
high_weapons = {'FIREARM','EXPLOSIVES','POISON'}
medium_weapons = {'KNIFE','BLUNT OBJECT'}
low_weapons = {'NOT DEFINED','OTHER','UNKNOWN'}

def label_severity(row):
    domain = str(row['Crime Domain']).upper()
    weapon = str(row['Weapon Used']).upper()
    police = 0
    try:
        police = int(row['Police Deployed'])
    except:
        pass
    sev = 'low'
    if domain == 'VIOLENT CRIME':
        if weapon in high_weapons:
            sev = 'high'
        elif weapon in medium_weapons:
            sev = 'medium'
        else:
            sev = 'medium'
    elif domain == 'FIRE ACCIDENT':
        if weapon in high_weapons:
            sev = 'high'
        elif weapon in medium_weapons:
            sev = 'medium'
        else:
            sev = 'low'
    elif domain == 'TRAFFIC FATALITY':
        if weapon in medium_weapons:
            sev = 'medium'
        else:
            sev = 'low'
    elif domain == 'OTHER CRIME':
        if weapon in high_weapons:
            sev = 'medium'
        else:
            sev = 'low'
    # escalation with police deployed
    if police >= 12:
        sev = 'high'
    elif police >=4:
        if sev == 'low':
            sev = 'medium'
        elif sev == 'medium':
            sev = 'high'
    return sev

df['severity'] = df.apply(label_severity, axis=1)

# Optional consolidation: uncomment to merge low and medium to 'non-high'
# df['severity'] = df['severity'].replace({'low':'non-high','medium':'non-high'})

df.info()

"""#Plots

**Distribution of Crime Severity**
"""

# Distribution of Crime Severity
plt.figure(figsize=(6,4))
sns.countplot(data=df, x='severity', order=df['severity'].value_counts().index, palette='viridis')
plt.title("Distribution of Crime Severity")
plt.xlabel("Severity")
plt.ylabel("Count")
plt.show()

"""High-severity crimes dominate the dataset, with medium and low crimes occurring far less frequently.

**City-Wise Crime Severity**
"""

plt.figure(figsize=(10,6))
sns.countplot(data=df, x='Region', hue='severity',
              order=df['Region'].value_counts().index,
              palette='Set2')

plt.title('City-wise Crime Severity', fontsize=16)
plt.xlabel('Region', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.xticks(rotation=45)
plt.legend(title='Severity')
plt.tight_layout()
plt.show()

"""West region reports the highest crime counts across all severities, followed by North and South, while Central has the least.

**Victim Age V/S Crime Severity**
"""

plt.figure(figsize=(8,6))
sns.countplot(data=df, x='Victim Age Group', hue='severity', palette='viridis')
plt.title("Victim Age vs Crime Severity")
plt.xlabel("Victim Age Group")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.show()

"""Adults face the highest crime severity, followed by seniors, while children and teenagers have comparatively fewer cases.

**Crimes By Month**
"""

#Extract date
df['Date Reported'] = pd.to_datetime(df['Date Reported'], errors='coerce')

# Extract month name
df['Month'] = df['Date Reported'].dt.month_name()

# Order months
month_order = ["January", "February", "March", "April", "May", "June",
               "July", "August", "September", "October", "November", "December"]

plt.figure(figsize=(12, 6))
sns.countplot(data=df, x='Month', hue='severity', order=month_order)
plt.title("Crimes by Month and Severity")
plt.xticks(rotation=45)
plt.show()

"""High-severity crimes dominate across all months, with May peaking slightly. Medium and low-severity crimes remain relatively stable year-round.

**Day V/S Night - Crime Severity**
"""

plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='Time of Day', hue='severity',
              order=['Day', 'Night'])
plt.title('Day vs Night - Crime Severity')
plt.xlabel('Time of Day')
plt.ylabel('Count')
plt.show()

"""Most severe crimes occur at night, often involving dangerous weapons.

**Weapon Type vs Crime Severity**
"""

plt.figure(figsize=(10, 5))
sns.countplot(data=df, x='Weapon Used', hue='severity',
              order=df['Weapon Used'].value_counts().index)
plt.title('Weapon Type vs Crime Severity')
plt.xlabel('Weapon Type')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

"""High-severity crimes dominate all weapon types, especially explosives, firearms, and blunt objects, while medium severity is higher for knives and unknown weapons. Low-severity cases are rare across the board.

**Police Deployment vs Crime Severity**
"""

plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='Police Deployed', hue='severity',
              order=df['Police Deployed'].value_counts().index)
plt.title('Police Deployment vs Crime Severity')
plt.xlabel('Police Deployment Level')
plt.ylabel('Count')
plt.show()

"""High-severity crimes remain consistently high across all police deployment levels, while medium and low severity show much lower counts.

**Stacked Bar Chart - Location V/S Crime Severity**
"""

location_severity = df.groupby(['Region', 'severity']).size().unstack(fill_value=0)

location_severity.plot(kind='bar', stacked=True, figsize=(12, 6))
plt.title('Location vs Crime Severity')
plt.xlabel('Location')
plt.ylabel('Count')
plt.legend(title='Severity')
plt.tight_layout()
plt.show()

"""High-severity crimes dominate across all locations, with North and West having the highest overall crime counts. Central reports the least crime activity, while low-severity cases remain minimal in every region.

**Victim Gender**
"""

gender_counts = df['Victim Gender'].value_counts()

# Creating Pie chart
plt.figure(figsize=(6, 6))
plt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('pastel'))
plt.title('Distribution of Victim Gender')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

# ----------------- 6. Encode target -----------------
le = LabelEncoder()
df['severity_encoded'] = le.fit_transform(df['severity'])
df.drop(columns=['Crime Domain','Weapon Used','severity'], inplace=True)

# ----------------- 7. Interaction Features -----------------
df['Crime_Region'] = df['Crime Description'] + '_' + df['Region']
df['Age_TimeOfDay'] = df['Victim Age Group'].astype(str) + '_' + df['Time of Day'].astype(str)
# Add gender-time interaction as well
df['Weapon_TimeOfDay'] = df['Victim Gender'] + '_' + df['Time of Day'].astype(str)

# ----------------- 8. CatBoost Categorical Features -----------------
cat_features = [
    'Crime Description', 'Victim Gender', 'Day', 'Time of Day', 'Region',
    'Victim Age Group', 'Crime_Region', 'Age_TimeOfDay', 'Weapon_TimeOfDay'
]

# ----------------- 9. Train-test split -----------------
X = df.drop(columns=['severity_encoded'])
y = df['severity_encoded']

# Perform the initial train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Create a smaller subset of the training data for faster tuning
# Adjust the subset_size as needed (e.g., 0.3 for 30% of the training data)
subset_size = 0.3
X_train_subset, _, y_train_subset, _ = train_test_split(
    X_train, y_train, train_size=subset_size, stratify=y_train, random_state=42
)

# Use the subset for subsequent steps like resampling and tuning
X_train = X_train_subset
y_train = y_train_subset


for c in cat_features:
    X_train[c] = X_train[c].astype(str)
    X_test[c] = X_test[c].astype(str)

# ----------------- 10. Helper: Resample with SMOTETomek -----------------
def resample_SMOTETomek(X, y, cat_cols):
    # Fill missing 'Police Deployed' values with the median
    if 'Police Deployed' in X.columns:
        X['Police Deployed'] = X['Police Deployed'].fillna(X['Police Deployed'].median())

    # Encode categorical columns temporarily as integers for SMOTE
    X_enc = X.copy()
    le_dict = {}
    for col in cat_cols:
        le_enc = LabelEncoder()
        X_enc[col] = le_enc.fit_transform(X_enc[col])
        le_dict[col] = le_enc
    smt = SMOTETomek(random_state=42)
    X_resampled, y_resampled = smt.fit_resample(X_enc, y)
    # Decode categorical columns back to original values
    for col in cat_cols:
        try:
            # Ensure the column exists in X_resampled before attempting inverse_transform
            if col in X_resampled.columns:
                 X_resampled[col] = le_dict[col].inverse_transform(X_resampled[col])
        except Exception:
            pass # Handle potential errors during inverse_transform
    return X_resampled, y_resampled

X_resampled, y_resampled = resample_SMOTETomek(X_train, y_train, cat_features)

for c in cat_features:
    X_resampled[c] = X_resampled[c].astype(str)

# ----------------- 11. Compute class weights -----------------
from sklearn.utils.class_weight import compute_class_weight
class_weights_arr = compute_class_weight('balanced', classes=np.unique(y_resampled), y=y_resampled)
class_weights = dict(zip(np.unique(y_resampled), class_weights_arr))

# ----------------- 12. Downloading -----------------
X_train.to_csv('X_train.csv', index=False)
y_train.to_csv('y_train.csv', index=False)
X_test.to_csv('X_test.csv', index=False)
y_test.to_csv('y_test.csv', index=False)
X_resampled.to_csv('X_resampled.csv', index=False)
y_resampled.to_csv('y_resampled.csv', index=False)

print("Datasets saved successfully!")

print(y_resampled.isnull().values.any())
print(y_resampled.isnull().values.any())
print(y_test.isnull().values.any())
print(X_test.isnull().values.any())
print(y_train.isnull().values.any())
print(X_train.isnull().values.any())